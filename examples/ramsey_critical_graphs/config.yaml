# Configuration for function minimization example
max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"

# LLM configuration
llm:
  primary_model: "meta-llama/llama-3.3-8b-instruct:free"
  primary_model_weight: 0.8
  secondary_model: "google/gemma-3n-e4b-it:free"
  secondary_model_weight: 0.2
  api_base: "https://openrouter.ai/api/v1"
  temperature: 0.7
  top_p: 0.95
  max_tokens: 4096

# Prompt configuration
prompt:
  system_message: "You are an expert programmer specializing in optimization algorithms and graph theory. Your task is to create a program that generates critical Ramsey graphs for given G1, G2."
  num_top_programs: 3
  use_template_stochasticity: true

# Database configuration
database:
  population_size: 5
  archive_size: 2
  num_islands: 2
  elite_selection_ratio: 0.2
  exploitation_ratio: 0.7

# Evaluator configuration
evaluator:
  timeout: 60
  cascade_evaluation: false
  cascade_thresholds: [0.5, 0.75]
  parallel_evaluations: 4
  use_llm_feedback: false

# Evolution settings
diff_based_evolution: true
allow_full_rewrites: true
